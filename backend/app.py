from flask import Flask, request, jsonify
from jinja2 import Template
import os
import together

# ‡πÉ‡∏ä‡πâ import ‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å langchain_community ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£ import ‡πÅ‡∏ö‡∏ö‡πÄ‡∏î‡∏¥‡∏°
from langchain_huggingface import HuggingFaceEmbeddings

from langchain_community.vectorstores import FAISS
import os
import together
from dotenv import load_dotenv

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤ environment variables ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .env


# ----- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏• -----
# ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô os.environ["TOGETHER_API_KEY"] = "..." ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
model_name = "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free"
together.api_key = "3c73cda46d9b41c8a1c58cc34871a660e50e94a220444eb72fb2bb3807f4c24e"

# ‡∏à‡∏≤‡∏Å‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô together.api_key ‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥

# ----- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Prompt Template ‡πÅ‡∏•‡∏∞ Model -----
system_prompt = """ 
You are an experienced veterinarian with a deep understanding of pet behavior and effective behavior correction techniques. Your advice should be clear, professional, and conversational, providing natural and friendly guidance to the pet owner. 

**Important:** Answer in Thai or English only. Do not include any other languages.

Please:
- Understand the pet owner's report and identify the main issues.
- Answer directly if a clear question is asked.
- Provide advice in a friendly, natural tone without being overly formal.
- Keep the final answer succinct and focused solely on addressing the pet owner's concern.
- Ensure your response is entirely in Thai (or English), with no foreign language terms.

### **Final Answer:**
(Provide a clear and natural answer in a friendly tone.)
"""

user_prompt = """Context (Pet owner's report):
{context}
---
Here is the question regarding your pet's behavior:

Question: {question}

### **Instructions:**
1. Identify the main issue from the report.
2. Answer in a natural, friendly tone as if speaking directly to the pet owner.
3. Keep your answer concise and focused solely on the concern.
4. **Important:** Ensure the answer is entirely in Thai or English only. Do not include words from any other language.

---
### **üîπ Response Format**
"""

chat_template_str = """
{% for message in messages %}
{% if message['role'] == 'system' %}
System: {{ message['content'] }}
{% elif message['role'] == 'user' %}
User: {{ message['content'] }}
{% elif message['role'] == 'assistant' %}
Assistant: {{ message['content'] }}
{% endif %}
{% endfor %}
{% if add_generation_prompt %}
Assistant:
{% endif %}
"""
chat_template = Template(chat_template_str)

def generate_chat_prompt(context, question):
    filled_user_prompt = user_prompt.format(context=context, question=question)
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": filled_user_prompt},
    ]
    return chat_template.render(messages=messages, add_generation_prompt=True)

# ----- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏• -----

def generate_response(model_name, final_prompt):
    response = together.Complete.create(
        model=model_name,
        prompt=final_prompt,
        max_tokens=520,
        temperature=0.1,
        stop=["Assistant:"],
        top_p=0.85
    )
    return response.get("choices", [{}])[0].get("text", "").strip()

# ----- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤ -----
def extract_context(retrieved_docs):
    """‡∏î‡∏∂‡∏á matched content ‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô context"""
    context = "\n".join([doc.page_content for doc in retrieved_docs])
    return context.strip()

# ----- ‡πÇ‡∏´‡∏•‡∏î Vector Store ‡∏î‡πâ‡∏ß‡∏¢ FAISS -----
# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ embeddings ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏• BAAI/bge-m3from langchain_huggingface import HuggingFaceEmbeddings
embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-m3")
faiss_index = FAISS.load_local(
    r"./faiss_index",  # ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç path ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå index ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
    embeddings,
    index_name="index",
    allow_dangerous_deserialization=True
)

# ----- ‡∏™‡∏£‡πâ‡∏≤‡∏á Flask App ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö API -----
app = Flask(__name__)

@app.route('/generate', methods=['POST'])
def generate():
    """
    ‡∏£‡∏±‡∏ö JSON payload ‡∏ó‡∏µ‡πà‡∏°‡∏µ key 'user_query'
    ‡πÅ‡∏•‡πâ‡∏ß‡πÉ‡∏ä‡πâ similarity search ‡πÅ‡∏•‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏†‡∏≤‡∏©‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö
    """
    data = request.get_json()
    if not data or 'user_query' not in data:
        return jsonify({'error': 'No user_query provided'}), 400

    user_query = data['user_query']

    # ‡∏î‡∏∂‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏î‡πâ‡∏ß‡∏¢ similarity search ‡∏à‡∏≤‡∏Å FAISS
    retrieved_docs = faiss_index.similarity_search(query=user_query, k=3)
    context = extract_context(retrieved_docs)

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á final prompt ‡∏î‡πâ‡∏ß‡∏¢ context ‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÅ‡∏•‡∏∞ user_query
    final_prompt = generate_chat_prompt(context, user_query)
    answer = generate_response(model_name, final_prompt)

    return jsonify({'answer': answer})

if __name__ == '__main__':
    # ‡∏£‡∏±‡∏ô Flask API ‡∏ö‡∏ô‡∏û‡∏≠‡∏£‡πå‡∏ï 5000 ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡∏ó‡∏∏‡∏Å IP (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Docker ‡∏´‡∏£‡∏∑‡∏≠ VM)
    app.run(host='0.0.0.0', port=8087)
